{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygdEaSP_o9nP"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_experimental\n",
        "!pip install underthesea\n",
        "!pip install langchain_huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGui5K_foUCC"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AP1eLnYMoRtO"
      },
      "outputs": [],
      "source": [
        "# from PyPDF2 import PdfReader\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForQuestionAnswering, pipeline\n",
        "import torch\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "# import easyocr\n",
        "# from ocr_tessa import fromPDFtoImg\n",
        "device = torch.device('cuda:0') # if using cuda settings is different\n",
        "# from verify import verify_qa\n",
        "# from test_sentence import semantic_chunk\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from underthesea import sent_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm-FZXFmofB9"
      },
      "outputs": [],
      "source": [
        "# material_path = \"ocr_material\"\n",
        "# pdf_name = \"dialy12.pdf\"\n",
        "# file_name = os.path.splitext(pdf_name)[0]\n",
        "# file_name = file_name.replace(' ', '_')\n",
        "# print(file_name)\n",
        "# pdf_file = os.path.join(material_path, pdf_name)\n",
        "# output_file = f\"qa_pairs_ocr/{file_name}/{file_name}_qa_pairs.json\"\n",
        "# open(output_file, 'w').close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SefHFYfNs1RA"
      },
      "outputs": [],
      "source": [
        "def create_output_folder(folder_path):\n",
        "    \"\"\"Tạo thư mục lưu trữ nếu chưa tồn tại.\"\"\"\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    print(f\"Tạo '{folder_path}'\")\n",
        "\n",
        "def save_text_to_file(text, output_path):\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "    print(f\"Lưu {output_path}\")\n",
        "\n",
        "# def clean_temp_folder(folder_path):\n",
        "#     shutil.rmtree(folder_path)\n",
        "#     print(f\"Xóa '{folder_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV_ImwFHq3Wx",
        "outputId": "7af9438b-8b8b-410f-e02f-88627b0a8870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dialy\n"
          ]
        }
      ],
      "source": [
        "material_path = \"ocr_material\"\n",
        "pdf_name = \"dialy.pdf\"\n",
        "txt_file_name = \"dialy.txt\"\n",
        "file_name = os.path.splitext(pdf_name)[0]\n",
        "file_name = file_name.replace(' ', '_')\n",
        "print(file_name)\n",
        "pdf_file = os.path.join(material_path, pdf_name)\n",
        "txt_file = os.path.join(material_path, txt_file_name)\n",
        "\n",
        "# output_file = f\"qa_pairs_ocr/{file_name}/{file_name}_qa_pairs.json\"\n",
        "output_file = f\"qa_pairs_ocr/{file_name}\"\n",
        "if not os.path.exists(output_file):\n",
        "    create_output_folder(output_file)\n",
        "# open(output_file, 'w').close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h19Ota0TolQK",
        "outputId": "eed34dc4-94d6-42fe-c5c9-b35943c301a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "model = HuggingFaceEmbeddings(model_name = 'dangvantuan/vietnamese-embedding')\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Initialize query model\n",
        "query_model_name = \"doc2query/msmarco-vietnamese-mt5-base-v1\"\n",
        "query_tokenizer = AutoTokenizer.from_pretrained(query_model_name)\n",
        "query_model = AutoModelForSeq2SeqLM.from_pretrained(query_model_name)\n",
        "\n",
        "# Initialize QA model\n",
        "qa_tokenizer = AutoTokenizer.from_pretrained(\"ancs21/xlm-roberta-large-vi-qa\")\n",
        "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"ancs21/xlm-roberta-large-vi-qa\")\n",
        "qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer, device=0) # CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-4kU1cjAousP"
      },
      "outputs": [],
      "source": [
        "# test_sentence\n",
        "def semantic_chunk(text, max_len=300):\n",
        "    sentences = text.split('. ')\n",
        "    chunks, current_chunk = [], \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if len(current_chunk) + len(sentence) <= max_len:\n",
        "            current_chunk += sentence + \". \"\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \". \"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def chunk_to_sub_paragraph(text, chunk_size=300):\n",
        "    l = sent_tokenize(text)\n",
        "    buffer = ''\n",
        "    chunk = []\n",
        "    for i in range(len(l)):\n",
        "        if (len(buffer) >= chunk_size):\n",
        "            chunk.append(buffer)\n",
        "            buffer = ''\n",
        "        else:\n",
        "            buffer += l[i]\n",
        "    return chunk\n",
        "\n",
        "def generate_queries(context):\n",
        "    input_ids = query_tokenizer.encode(context, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        queries = query_model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=150,  # Adjust length\n",
        "            num_beams=5,  # Increase beam size\n",
        "            no_repeat_ngram_size=3,  # Avoid repetitions\n",
        "            num_return_sequences=3,  # More queries for variety\n",
        "        )\n",
        "    return [query_tokenizer.decode(q, skip_special_tokens=True) for q in queries]\n",
        "\n",
        "def generate_answer(question, context):\n",
        "    result = qa_pipeline({\"question\": question, \"context\": context})\n",
        "    return result['answer']\n",
        "\n",
        "# def clean_text(text):\n",
        "#     # Remove page numbers like \"Trang 123\" or \"Page 123\"\n",
        "#     text = re.sub(r'\\b(?:Trang)\\s*\\d+\\b', '', text)\n",
        "#     # Remove figures labeled \"Hình:\" or similar patterns\n",
        "#     text = re.sub(r'\\b(?:Hình|Hinh)\\s*.*?(?=\\n|$)', '', text)\n",
        "#     # Remove extra whitespace and newlines\n",
        "#     text = re.sub(r'\\s+', ' ', text).strip()\n",
        "#     return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl6auz6poyt5",
        "outputId": "cf21ca5a-e1fd-456a-ceb8-28239cddaddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n",
            "QA pairs saved to qa_pairs_ocr/dialy/dialy_qa_pairs.json\n"
          ]
        }
      ],
      "source": [
        "os.makedirs(os.path.join('qa_pairs_ocr', file_name), exist_ok=True)\n",
        "question_existed = []\n",
        "counter = 1\n",
        "qa_pairs = []\n",
        "\n",
        "# Process each page from the text file\n",
        "with open(txt_file, \"r\", encoding=\"utf-8\") as txt_reader:\n",
        "    page_data = txt_reader.read()\n",
        "    pages = re.split(r'Page \\d+:', page_data)\n",
        "\n",
        "    for i, page_content in enumerate(pages):\n",
        "        if not page_content.strip():\n",
        "            continue\n",
        "\n",
        "        # text = clean_text(page_content)\n",
        "        text = page_content\n",
        "        sentences_list = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "        if len(sentences_list) > 1:\n",
        "            chunks = chunk_to_sub_paragraph(text)\n",
        "        else:\n",
        "            chunks = sentences_list\n",
        "\n",
        "        # Log extracted text and chunks\n",
        "        with open(\"log.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"All text is : {text}, and chunks is : {chunks}\\n\")\n",
        "\n",
        "        # Generate QA pairs for each chunk\n",
        "        for chunk in chunks:\n",
        "            if not chunk.strip() or chunk.isnumeric():\n",
        "                continue\n",
        "            questions = generate_queries(chunk)\n",
        "            questions_set = set(questions)\n",
        "\n",
        "            for question in questions_set:\n",
        "                counter += 1\n",
        "                if not question.strip():\n",
        "                    continue  # Skip empty questions\n",
        "                if question not in question_existed:\n",
        "                    answer = generate_answer(question, chunk)\n",
        "                    # if verify_qa(chunk, question, answer):\n",
        "                    qa_pairs.append({\"id\": f\"{file_name}_p_{i + 1}_{counter}\", \"question\": question, \"answer\": answer, \"context\": chunk})\n",
        "                    question_existed.append(question)\n",
        "\t\t\n",
        "\t\t# check folder\n",
        "        os.makedirs(os.path.join('qa_pairs_ocr', file_name), exist_ok=True)\n",
        "        output_file = os.path.join('qa_pairs_ocr', file_name, f\"{file_name}_qa_pairs.json\")\n",
        "        \n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(qa_pairs, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "        print(f\"QA pairs saved to {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
