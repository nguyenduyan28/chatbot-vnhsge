# LLMâ€‘powered QA Pipeline for Vietnamese National Highâ€‘School Exams
*A complete workflow that converts scanned textbooks & pastâ€‘papers into validated multipleâ€‘choice questionâ€“answer (QA) pairs.*

---

## 1â€‚Project Overview
This repository contains an **endâ€‘toâ€‘end largeâ€‘languageâ€‘model (LLM) pipeline** for building structured QA datasets from Vietnamese educational content (THPT QG level).  
It automates:

1. **OCR** â€“ recognise text from PDF/PNG pages.  
2. **Question & answer generation** â€“ leverage open LLMs to suggest candidate MCQs.  
3. **Automatic verification** â€“ filter out wrong or malformed pairs.  
4. **Dataset curation & lightweight fineâ€‘tuning** â€“ teach a base model to produce higherâ€‘quality answers.

---

## 2â€‚Repository Layout

```
.
â”œâ”€â”€ Final/                   # Curated datasets, final notebooks & report
â”‚   â”œâ”€â”€ *.json               # Final QA pairs
â”‚   â”œâ”€â”€ final_finetune*.ipynb
â”‚   â”œâ”€â”€ Reportâ€‘NLP.pdf
â”‚   â””â”€â”€ flow.txt             # Highâ€‘level pipeline diagram
â”‚
â”œâ”€â”€ OCR_LLM/                 # Standâ€‘alone OCR + QA generator demo
â”‚   â”œâ”€â”€ ocr_material/        # Example raw text extracted by OCR
â”‚   â”œâ”€â”€ qa_pairs_ocr/        # QA pairs generated from OCR output
â”‚   â”œâ”€â”€ ocrLLM.py            # CLI: OCR â†’ QA JSON
â”‚   â””â”€â”€ *.ipynb              # Colab experiments
â”‚
â”œâ”€â”€ qa_pairs_ocr/            # Additional generated QA datasets (grouped by subject)
â”‚
â”œâ”€â”€ ocr_material/            # Source PDFs used for local OCR tests
â”‚
â”œâ”€â”€ output/                  # Intermediate logs / plainâ€‘text dumps
â”‚
â”œâ”€â”€ verification/            # Verified subsets saved by `verify.py`
â”‚
â”œâ”€â”€ testing/                 # Heldâ€‘out QA sets for evaluation
â”‚
â”œâ”€â”€ scripts & utilities
â”‚   â”œâ”€â”€ Verification.py      # Batchâ€‘level verifier
â”‚   â”œâ”€â”€ verify.py            # Wrapper around verifier model
â”‚   â”œâ”€â”€ verifyâ€‘test.py       # Quick smokeâ€‘test script
â”‚   â”œâ”€â”€ pdf2question.py      # Shortcut script: PDF â†’ QA JSON
â”‚   â”œâ”€â”€ combine_data.py      # Merge multiple QA JSONs
â”‚   â”œâ”€â”€ extract_ocr.py       # Tesseract bulk OCR helper
â”‚   â””â”€â”€ ocr_tessa.py         # Minimal Tesseract OCR example
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # â† you are here
```


---

## 3â€‚Installation

> **Prerequisites:** Pythonâ€¯â‰¥â€¯3.10, Git, and a CUDAâ€‘capable GPU if you want to run the LLM stages locally.

```bash
# 1) Create & activate virtual env
python -m venv .venv
source .venv/bin/activate           # Windows: .venv\Scripts\activate

# 3) Install dependencies (PyTorch will autoâ€‘detect GPU vs CPU)
pip install -r requirements.txt

# 4) (Optional) Install Tesseract for fastest local OCR
sudo apt-get update && sudo apt-get install tesseract-ocr
```

---

## 4â€‚Quick Start

### 4.1â€‚OCR â†’ QA pairs in one shot

```bash
python OCR_LLM/ocrLLM.py \
       --pdf ocr_material/"Dia Ly 12.pdf" \
       --out qa_pairs_ocr/Lich_su_12/Lich_su_12_qa_pairs.json \
       --engine vintern            # or "tesseract"
```

### 4.2â€‚Stepâ€‘byâ€‘step pipeline

1. **Bulk OCR**

   ```bash
   python extract_ocr.py \
          --input-dir ocr_material \
          --output-dir output/ocr_json \
          --engine tesseract
   ```

2. **Question generation**

   ```bash
   python pdf2question.py \
          --ocr-json output/ocr_json/lichsu12_tessa.txt \
          --out qa_pairs_ocr/Lich_su_12/Lich_su_12_qa_pairs_1.json
   ```

3. **Verification**

   ```bash
   python verify.py \
          --qa-json qa_pairs_ocr/Lich_su_12/Lich_su_12_qa_pairs_1.json \
          --out verification/verified_qa_pairs_10.json
   ```

4. **(Optional) Fineâ€‘tune base model**

   Open and run `Final/final_finetune.ipynb` â€“ the notebook trains LoRA adapters for `LLaMAâ€‘2â€‘7Bâ€‘chat`.

---

## 5â€‚Configuration

Most scripts accept `--help` for all flags.  
YAML configs used by the Colab / Jupyter notebooks live in `Final/flow.txt` and inline notebook cells.

Key environment variables:

| Variable | Purpose |
|----------|---------|
| `HF_TOKEN` | Hugging Face access token for gated LLM/OCR models |
| `CUDA_VISIBLE_DEVICES` | Select GPU(s) for generation / training |

---

## 6â€‚Evaluation

Run:

```bash
python verifyâ€‘test.py
```

This script loads a random subset from `testing/qa_pairs_*.json` and reports:

* **Exact Match (EM)** and **F1**  
* **BLEU / ROUGEâ€‘L** (for generative answers)  
* **Verifier passâ€‘rate** (LLMâ€‘based judge)

Results are written to `output/eval_log.txt`.

---
---

## ðŸ”§ AI Techniques Used

This project integrates multiple AI and NLP methods across the pipeline:

- **Optical Character Recognition (OCR)**  
  - Classical: `Tesseract-OCR` for lightweight, local character recognition.  
  - Advanced: `Vintern 1B v2` â€” a large language model for image-to-text OCR, combining:
    - `InternViT-300M` for visual recognition.
    - `Qwen2-0.5B-Instruct` for multilingual text interpretation.

- **Text Chunking & Preprocessing**  
  - Implemented both **semantic chunking** and **recursive chunking** to split scanned pages into meaning-preserving units.

- **Question Generation**  
  - Used `msmarco-vietnamese-mt5-base-v1`, a Vietnamese fine-tuned sequence-to-sequence model based on mT5, capable of generating contextually relevant questions from OCR'd text.

- **Answer Generation**  
  - Deployed `xlm-roberta-large-vi-qa` for extractive QA. The model handles both questionâ€“context alignment and answer span extraction from Vietnamese texts.

- **Answer Verification**  
  - Adopted `Meta-LLaMA-3-8B-Instruct` to filter invalid answers and ensure logical correctness via LLM-based feedback.

- **Fine-tuning & Training**  
  - Applied **quantization** via `bitsandbytes` to reduce memory use (4-bit & 8-bit support).
  - Used **LoRA (Low-Rank Adaptation)** from Hugging Face `PEFT` to perform **parameter-efficient fine-tuning** (PET) on top of `LLaMA-2-7B-chat`.
  - All training done with **HuggingFace Transformers**, `Accelerate`, and custom dataset pipelines.
